{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "import xarray as xr\n",
    "import codecs\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_get_realdata(file_full_path: str, split_hours=72, issue_hours_steps: int = 12) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        TODO:[-] 25-04-23 生成实况训练数据集\n",
    "        从指定文件批量获取时间数据并以dataframe的形式返回\n",
    "    :param file_full_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        eg: csv文件样例:\n",
    "                        time\tlongitude\tlatitude\tWS\tYBG\n",
    "                        202401010000\n",
    "                        YYYYMMDDHHmm\n",
    "    \"\"\"\n",
    "    list_series = []\n",
    "    merge_dict = {}\n",
    "    if pathlib.Path(file_full_path).exists():\n",
    "        # ds: xr.Dataset = xr.open_dataset(file_full_path)\n",
    "        df: pd.DataFrame = pd.read_csv(file_full_path)\n",
    "        \"\"\"读取指定路径的浮标处理后的一年的数据\"\"\"\n",
    "        # 通过起止时间找到对应的index，然后每次的发布时间间隔步长为12h\n",
    "\n",
    "        # step1: 生成2024年一年的时间步长为1hour的时间索引集合\n",
    "        start_time = '2024-01-01 00:00:00'\n",
    "        end_time = '2024-12-31 23:00:00'\n",
    "        time_series = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "\n",
    "        # 将time列的内容从int64 => str\n",
    "        df['time'] = df['time'].astype(str)\n",
    "        df['time'] = pd.to_datetime(df['time'], format='%Y%m%d%H%M')\n",
    "        # step2: 将 time列设置为index，并将index替换为标准时间集合\n",
    "        df.set_index('time', inplace=True)\n",
    "        df_reindexed = df.reindex(time_series)\n",
    "        df_reindexed.index.name = 'time'\n",
    "\n",
    "        # step3: 生成12小时为间隔的时间数组\n",
    "        freq_str: str = f'{issue_hours_steps}H'\n",
    "        issue_dt_series = pd.date_range(start=start_time, end=end_time, freq=freq_str)\n",
    "\n",
    "        for temp_time in issue_dt_series:\n",
    "            temp_index: int = df_reindexed.index.get_loc(temp_time)\n",
    "            val_series = df_reindexed[temp_index:temp_index + split_hours]\n",
    "            list_series.append(val_series)\n",
    "        # TODO:[-] 25-04-24 此处做重新修改，拼接成一个dataframe\n",
    "\n",
    "        for temp_time in issue_dt_series:\n",
    "            dt_str: str = temp_time.strftime('%Y%m%d%H%M%S')\n",
    "            temp_index: int = df_reindexed.index.get_loc(temp_time)\n",
    "            val_series = df_reindexed[temp_index:temp_index + split_hours]\n",
    "            # 此处改为只取 'WS' 列\n",
    "            # TODO:[-] 25-04-24 住一次此处需要将每一个 series的index索引重置为 [0,71]\n",
    "            merge_dict[dt_str] = val_series['WS'].reset_index(drop=True)\n",
    "            # list_series.append(val_series)\n",
    "    df = pd.DataFrame.from_dict(merge_dict)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evase\\AppData\\Local\\Temp\\ipykernel_53672\\253962976.py:26: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_series = pd.date_range(start=start_time, end=end_time, freq='H')\n",
      "C:\\Users\\evase\\AppData\\Local\\Temp\\ipykernel_53672\\253962976.py:38: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  issue_dt_series = pd.date_range(start=start_time, end=end_time, freq=freq_str)\n"
     ]
    }
   ],
   "source": [
    "read_path: str = r'Z:\\WIND\\GRAPES\\2024'\n",
    "out_put_path: str = r'./data'\n",
    "out_put_file_path: str = str(pathlib.Path(out_put_path) / 'GRAPES_2024_24')\n",
    "lat: float = 39.5003\n",
    "lng: float = 120.59533\n",
    "read_file_full_path: str = r'G:\\05DATA\\01TRAINING_DATA\\FUB\\MF01001\\2024_local.csv'\n",
    "# step1: 生成一年的 365*2 =730 个 ws,ybg -> 只取 ws\n",
    "df = batch_get_realdata(read_file_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20240101000000</th>\n",
       "      <th>20240101120000</th>\n",
       "      <th>20240102000000</th>\n",
       "      <th>20240102120000</th>\n",
       "      <th>20240103000000</th>\n",
       "      <th>20240103120000</th>\n",
       "      <th>20240104000000</th>\n",
       "      <th>20240104120000</th>\n",
       "      <th>20240105000000</th>\n",
       "      <th>20240105120000</th>\n",
       "      <th>...</th>\n",
       "      <th>20241227000000</th>\n",
       "      <th>20241227120000</th>\n",
       "      <th>20241228000000</th>\n",
       "      <th>20241228120000</th>\n",
       "      <th>20241229000000</th>\n",
       "      <th>20241229120000</th>\n",
       "      <th>20241230000000</th>\n",
       "      <th>20241230120000</th>\n",
       "      <th>20241231000000</th>\n",
       "      <th>20241231120000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   20240101000000  20240101120000  20240102000000  20240102120000  \\\n",
       "0            10.4             8.1            10.4             1.5   \n",
       "1            10.1             9.3            10.4             1.2   \n",
       "2             7.9            10.6            10.8             1.7   \n",
       "3             6.9             9.8            10.1             1.7   \n",
       "4             5.7            11.3             9.4             2.6   \n",
       "\n",
       "   20240103000000  20240103120000  20240104000000  20240104120000  \\\n",
       "0             2.7             5.5             9.8             8.2   \n",
       "1             3.0             3.1             9.8             8.9   \n",
       "2             2.7             1.2             9.4             6.8   \n",
       "3             3.8             1.3            10.3             8.8   \n",
       "4             3.6             3.4            10.9             8.7   \n",
       "\n",
       "   20240105000000  20240105120000  ...  20241227000000  20241227120000  \\\n",
       "0             6.7             0.8  ...             5.4             7.5   \n",
       "1             5.9             2.1  ...             5.6             6.0   \n",
       "2             7.2             2.4  ...             5.2             6.6   \n",
       "3             8.8             3.5  ...             7.7             7.0   \n",
       "4            10.1             3.8  ...             7.6             7.5   \n",
       "\n",
       "   20241228000000  20241228120000  20241229000000  20241229120000  \\\n",
       "0             8.4             6.5             4.8            10.2   \n",
       "1             8.3             7.7             4.8            11.3   \n",
       "2             7.6             7.7             4.5            11.2   \n",
       "3             7.4             8.1             5.2            11.8   \n",
       "4             6.8             7.5             5.1            11.0   \n",
       "\n",
       "   20241230000000  20241230120000  20241231000000  20241231120000  \n",
       "0             8.8             7.2             8.1             7.6  \n",
       "1             8.7             5.0             8.6             9.1  \n",
       "2            10.8             3.9             7.5            10.0  \n",
       "3            11.5             4.2             7.0            11.0  \n",
       "4            10.6             4.2             5.7            10.7  \n",
       "\n",
       "[5 rows x 732 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_readncfiles(read_path: str, lat: float, lng: float, month: int = 1):\n",
    "    \"\"\"\n",
    "        根据指定路径遍历该路径下的所有文件，并读取每个文件中的[0,23]h的时序数据(根据经纬度)\n",
    "    :param read_path: 读取nc的根目录\n",
    "    :param lat:\n",
    "    :param lng:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df_nc: xr.Dataset = None\n",
    "    nc_path = pathlib.Path(read_path)\n",
    "    df_dict: dict = {}\n",
    "    for file in nc_path.iterdir():\n",
    "        # for file in 'GRAPES_2024010100_240h_UV.nc','GRAPES_2024010112_240h_UV.nc':\n",
    "        # 修改为按月切分\n",
    "        if file.is_file():\n",
    "            # 获取当前文件的 datetime 字符串\n",
    "            dt_str: str = file.name.split('_')[1]\n",
    "            dt_arrow = arrow.get(dt_str, 'YYYYMMDDHH')\n",
    "            temp_month = dt_arrow.month\n",
    "            if month == temp_month:\n",
    "                # step1: 拼接成文件全路径\n",
    "                # file_full_path = nc_path / file\n",
    "                file_full_path_str: str = str(file)\n",
    "                # step2: 使用 xarray.open_dataset 打开 netcdf文件\n",
    "                temp_df: xr.Dataset = xr.open_dataset(file_full_path_str)\n",
    "                # 注意: 打开的 Dataset 有三个维度,目前只需要按照经纬度提取几个位置的24h内的时序数据\n",
    "                if temp_df is not None:\n",
    "                    \"\"\"\n",
    "                        Coordinates:\n",
    "                        * latitude             (latitude) float64 -89.94 -89.81 -89.69 ... 89.81 89.94\n",
    "                        * longitude            (longitude) float64 0.0 0.125 0.25 ... 359.8 359.9\n",
    "                        * time                 (time) datetime64[ns] 2024-01-01 ... 2024-01-11\n",
    "                        Data variables:\n",
    "                            UGRD_10maboveground  (time, latitude, longitude) float32 ...\n",
    "                            VGRD_10maboveground  (time, latitude, longitude) float32 ...\n",
    "                    \"\"\"\n",
    "                    # 从该文件中提取指定经纬度的时序数据\n",
    "                    filter_ds = temp_df.sel(latitude=lat, longitude=lng, method='nearest')\n",
    "                    # 分别取出 u 与 v 分量\n",
    "                    u_vals = filter_ds['UGRD_10maboveground'].values[:25]\n",
    "                    v_vals = filter_ds['VGRD_10maboveground'].values[:25]\n",
    "                    dt_vals = filter_ds['time'].values\n",
    "                    dt64_forecast_start = dt_vals[0]\n",
    "                    dt_forecast_start: datetime = pd.to_datetime(dt64_forecast_start)\n",
    "                    dt_forecast_start_str: str = dt_forecast_start.strftime('%Y%m%d%H%M%S')\n",
    "                    temp_u_column_name: str = f'{dt_forecast_start_str}_u'\n",
    "                    temp_v_column_name: str = f'{dt_forecast_start_str}_v'\n",
    "                    df_dict[temp_u_column_name] = u_vals\n",
    "                    df_dict[temp_v_column_name] = v_vals\n",
    "                    print(f\"读取{file_full_path_str}成功\")\n",
    "                else:\n",
    "                    df_nc = temp_df\n",
    "    # 将最终的 dict -> pd.DataFrame\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    print('生成最终DataFrame ing ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_readncfiles_byyears(read_path: str, lat: float, lng: float, year: int = 2024):\n",
    "    \"\"\"\n",
    "        根据指定路径遍历该路径下的所有文件，并读取每个文件中的[0,23]h的时序数据(根据经纬度)\n",
    "    :param read_path: 读取nc的根目录\n",
    "    :param lat:\n",
    "    :param lng:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df_nc: xr.Dataset = None\n",
    "    nc_path = pathlib.Path(read_path)\n",
    "    df_dict: dict = {}\n",
    "    for file in nc_path.iterdir():\n",
    "        # for file in 'GRAPES_2024010100_240h_UV.nc','GRAPES_2024010112_240h_UV.nc':\n",
    "        # 修改为按月切分\n",
    "        if file.is_file():\n",
    "            # 获取当前文件的 datetime 字符串\n",
    "            dt_str: str = file.name.split('_')[1]\n",
    "            dt_arrow = arrow.get(dt_str, 'YYYYMMDDHH')\n",
    "            temp_year = dt_arrow.year\n",
    "            if year == temp_year:\n",
    "                # step1: 拼接成文件全路径\n",
    "                # file_full_path = nc_path / file\n",
    "                file_full_path_str: str = str(file)\n",
    "                # step2: 使用 xarray.open_dataset 打开 netcdf文件\n",
    "                temp_df: xr.Dataset = xr.open_dataset(file_full_path_str)\n",
    "                # 注意: 打开的 Dataset 有三个维度,目前只需要按照经纬度提取几个位置的24h内的时序数据\n",
    "                if temp_df is not None:\n",
    "                    \"\"\"\n",
    "                        Coordinates:\n",
    "                        * latitude             (latitude) float64 -89.94 -89.81 -89.69 ... 89.81 89.94\n",
    "                        * longitude            (longitude) float64 0.0 0.125 0.25 ... 359.8 359.9\n",
    "                        * time                 (time) datetime64[ns] 2024-01-01 ... 2024-01-11\n",
    "                        Data variables:\n",
    "                            UGRD_10maboveground  (time, latitude, longitude) float32 ...\n",
    "                            VGRD_10maboveground  (time, latitude, longitude) float32 ...\n",
    "                    \"\"\"\n",
    "                    # 从该文件中提取指定经纬度的时序数据\n",
    "                    filter_ds = temp_df.sel(latitude=lat, longitude=lng, method='nearest')\n",
    "                    # 分别取出 u 与 v 分量\n",
    "                    u_vals = filter_ds['UGRD_10maboveground'].values[:25]\n",
    "                    v_vals = filter_ds['VGRD_10maboveground'].values[:25]\n",
    "                    dt_vals = filter_ds['time'].values\n",
    "                    dt64_forecast_start = dt_vals[0]\n",
    "                    dt_forecast_start: datetime = pd.to_datetime(dt64_forecast_start)\n",
    "                    dt_forecast_start_str: str = dt_forecast_start.strftime('%Y%m%d%H%M%S')\n",
    "                    temp_u_column_name: str = f'{dt_forecast_start_str}_u'\n",
    "                    temp_v_column_name: str = f'{dt_forecast_start_str}_v'\n",
    "                    df_dict[temp_u_column_name] = u_vals\n",
    "                    df_dict[temp_v_column_name] = v_vals\n",
    "                    print(f\"读取{file_full_path_str}成功\")\n",
    "                else:\n",
    "                    df_nc = temp_df\n",
    "    # 将最终的 dict -> pd.DataFrame\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    print('生成最终DataFrame ing ')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010100_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010112_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010200_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010212_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010300_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010312_240h_UV.nc成功\n",
      "读取Z:\\WIND\\GRAPES\\2024\\GRAPES_2024010400_240h_UV.nc成功\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_wind \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_readncfiles_byyears\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 41\u001b[0m, in \u001b[0;36mbatch_readncfiles_byyears\u001b[1;34m(read_path, lat, lng, year)\u001b[0m\n\u001b[0;32m     39\u001b[0m filter_ds \u001b[38;5;241m=\u001b[39m temp_df\u001b[38;5;241m.\u001b[39msel(latitude\u001b[38;5;241m=\u001b[39mlat, longitude\u001b[38;5;241m=\u001b[39mlng, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 分别取出 u 与 v 分量\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m u_vals \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGRD_10maboveground\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m[:\u001b[38;5;241m25\u001b[39m]\n\u001b[0;32m     42\u001b[0m v_vals \u001b[38;5;241m=\u001b[39m filter_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVGRD_10maboveground\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m25\u001b[39m]\n\u001b[0;32m     43\u001b[0m dt_vals \u001b[38;5;241m=\u001b[39m filter_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\dataarray.py:733\u001b[0m, in \u001b[0;36mDataArray.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03m    The array's data as a numpy.ndarray.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;124;03m    type does not support coercion like this (e.g. cupy).\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\variable.py:614\u001b[0m, in \u001b[0;36mVariable.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\variable.py:314\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[0;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\indexing.py:693\u001b[0m, in \u001b[0;36mMemoryCachedArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\indexing.py:696\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\indexing.py:690\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\indexing.py:664\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\core\\indexing.py:551\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 551\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\coding\\variables.py:71\u001b[0m, in \u001b[0;36m_ElementwiseFunctionArray.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\evase\\Anaconda3\\envs\\py39\\lib\\site-packages\\xarray\\backends\\scipy_.py:72\u001b[0m, in \u001b[0;36mScipyArrayWrapper.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Copy data if the source file is mmapped. This makes things consistent\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# with the netCDF4 library by ensuring we can safely read arrays even\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# after closing associated files.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39muse_mmap\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_wind = batch_readncfiles_byyears(read_path, lat, lng, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
